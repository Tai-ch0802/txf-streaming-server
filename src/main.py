'''
==========================================
TXF Streaming Producer (Shioaji -> Kafka Protobuf)
------------------------------------------
Description: é€£æ¥æ°¸è± Shioaji API æ¥æ”¶å°æŒ‡æœŸ Tick / BidAskï¼Œé€é Protobuf æ¨é€ Kafka
Architecture:
  - Process Management: Systemd
  - Concurrency: asyncio
  - Serialization: Google Protobuf
  - Transport: confluent-kafka
  - Logging: stdout captured by systemd
Author: Garrett & Gemini
Last Updated: 2025-11-28
==========================================
'''

import sys, asyncio, logging
from datetime import datetime
from decimal import Decimal
from typing import Optional
import shioaji as sj
from shioaji import TickFOPv1, BidAskFOPv1
from confluent_kafka import Producer
import txf_data_pb2
from config import (
    SHIOAJI_API_KEY, SHIOAJI_SECRET_KEY, 
    KAFKA_BOOTSTRAP_SERVERS, 
    TICK_TOPIC, BIDASK_TOPIC
)

# ==========================================
# Logging Configuration
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger("TXF_Producer")

# ==========================================
# Global Constants & Configuration
# ==========================================
API_INSTANCE: Optional[sj.Shioaji] = None  # å…¨åŸŸ API å¯¦ä¾‹
SCALE = 10000  # åƒ¹æ ¼ç¸®æ”¾å€æ•¸ (ç¬¦åˆ proto)
FATAL_CODES = {1,2,8}  # è‡´å‘½éŒ¯èª¤ç¢¼

KAFKA_CONFIG = {
    'bootstrap.servers': KAFKA_BOOTSTRAP_SERVERS,
    'client.id': 'txf-producer-hft',
    'acks': '0', 'linger.ms': 0, 'compression.type': 'lz4',
    'queue.buffering.max.kbytes': 131072, 'batch.size': 262144,
    'socket.send.buffer.bytes': 102400, 'socket.receive.buffer.bytes': 102400,
}

try:
    producer = Producer(KAFKA_CONFIG)
except Exception as e:
    logger.critical(f"âŒ Kafka Producer Initialization Failed: {e}")
    sys.exit(1)

# ==========================================
# Helper Functions
# ==========================================
def delivery_report(err, msg):
    """Kafka å‚³é€å›èª¿ (åƒ…ç”¨æ–¼éŒ¯èª¤è¨˜éŒ„)"""
    if err: logger.error(f'âŒ Message delivery failed: {err}')

def to_scaled_int(val: Optional[Decimal]) -> int:
    """å°‡ Decimal/Float è½‰æ›ç‚º int64 (x10000)"""
    if val is None: return 0
    return int(val * SCALE)

# ==========================================
# Core Processing Logic (Protobuf Packing)
# ==========================================
def process_tick(quote: TickFOPv1):
    """è™•ç† Tick æ•¸æ“š"""
    try:
        if quote.simtrade == 1: return
        tick = txf_data_pb2.Tick()
        tick.code = quote.code
        tick.timestamp_ms = int(quote.datetime.timestamp()*1000)
        tick.tick_type = int(quote.tick_type)
        tick.close = to_scaled_int(quote.close)
        tick.volume = int(quote.volume)
        tick.underlying_price = to_scaled_int(quote.underlying_price)
        tick.total_volume = int(quote.total_volume)

        producer.produce(
            TICK_TOPIC,
            key=tick.code.encode('utf-8'),
            value=tick.SerializeToString(),
            on_delivery=delivery_report
        )
        producer.poll(0)
    except Exception as e:
        logger.error(f"âŒ Error processing tick: {e}")

def process_bidask(quote: BidAskFOPv1):
    """è™•ç† BidAsk æ•¸æ“š"""
    try:
        if quote.simtrade == 1: return
        ba = txf_data_pb2.BidAsk()
        ba.code = quote.code
        ba.timestamp_ms = int(quote.datetime.timestamp()*1000)
        ba.bid_total_vol = int(quote.bid_total_vol)
        ba.ask_total_vol = int(quote.ask_total_vol)
        ba.bid_price.extend([to_scaled_int(x) for x in quote.bid_price])
        ba.ask_price.extend([to_scaled_int(x) for x in quote.ask_price])
        ba.bid_volume.extend(quote.bid_volume)
        ba.ask_volume.extend(quote.ask_volume)
        ba.diff_bid_vol.extend(quote.diff_bid_vol)
        ba.diff_ask_vol.extend(quote.diff_ask_vol)

        producer.produce(
            BIDASK_TOPIC,
            key=ba.code.encode('utf-8'),
            value=ba.SerializeToString(),
            on_delivery=delivery_report
        )
        producer.poll(0)
    except Exception as e:
        logger.error(f"âŒ Error processing bidask: {e}")

# ==========================================
# Session & Event Handling
# ==========================================
def handle_session_down(reason="Retries Timeout"):
    """è™•ç† Session Down äº‹ä»¶ï¼ŒSystemd æœƒè‡ªå‹•é‡å•Ÿ"""
    global API_INSTANCE
    logger.critical(f"ğŸš¨ API Session Down Detected: {reason}")
    logger.critical("ğŸ›‘ Terminating to force clean API recreation via Systemd...")
    try: API_INSTANCE.logout()
    except: pass
    producer.flush()
    sys.exit(1)

def quote_event_handler(resp_code, event_code, info, event):
    """Solace Event Code è™•ç†"""
    if event_code in {0,6,10,13,15,16,18}:
        if event_code==13: logger.info("âœ… Solace é‡é€£æˆåŠŸ")
        return
    if event_code==12:
        logger.warning("â³ Solace æ­£åœ¨è‡ªå‹•é‡è©¦...")
        return
    if event_code in FATAL_CODES:
        logger.error(f"âŒ è‡´å‘½éŒ¯èª¤ (Code {event_code}): {info}")
        handle_session_down(f"Fatal Event Code {event_code}: {info}")
    logger.warning(f"[SOLACE EVENT] Unhandled Code {event_code}: {info}")

# ==========================================
# Debug Logging
# ==========================================
def log_tick_debug(tick: TickFOPv1):
    """Debug Tick Log"""
    if not logger.isEnabledFor(logging.DEBUG): return
    latency_ms = (datetime.now()-tick.datetime).total_seconds()*1000
    logger.debug(
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
        f"Tick {tick.code} ({tick.total_volume} Lot)\n"
        f"æˆäº¤æ™‚é–“: {tick.datetime}\n"
        f"æ¥æ”¶æ™‚é–“: {datetime.now()}\n"
        f"å»¶   é²: {latency_ms:.3f} ms\n"
        f"åƒ¹   æ ¼: {tick.close}, tick_type: {tick.tick_type}\n"
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    )

def log_bidask_debug(bidask: BidAskFOPv1):
    """Debug BidAsk Log"""
    if not logger.isEnabledFor(logging.DEBUG): return
    logger.debug(
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
        f"ğŸ“Š BidAsk {bidask.datetime}\n"
        f"Bid: {bidask.bid_price[0]}, Ask: {bidask.ask_price[0]}\n"
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    )

# ==========================================
# Main Async Execution
# ==========================================
async def main_async():
    """
    TXF Streaming Producer ä¸»æµç¨‹ (Async ç‰ˆæœ¬)
    - ç™»å…¥ Shioaji API
    - è¨»å†Šäº‹ä»¶å›èª¿ (Session Down / Solace / Tick / BidAsk)
    - è¨‚é–±å°æŒ‡æœŸè¡Œæƒ…
    - æ°¸é ç­‰å¾…äº‹ä»¶å›èª¿
    - Ctrl+C æˆ–ç•°å¸¸è§¸ç™¼å„ªé›…é€€å‡º
    """
    global API_INSTANCE
    API_INSTANCE = sj.Shioaji(simulation=True)

    # --- API ç™»å…¥ ---
    logger.info("ğŸ”‘ ç™»å…¥ Shioaji API...")
    try:
        API_INSTANCE.login(api_key=SHIOAJI_API_KEY, secret_key=SHIOAJI_SECRET_KEY)
        logger.info("âœ… ç™»å…¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ ç™»å…¥å¤±æ•—: {e}")
        sys.exit(1)

    # --- è¨»å†Šå›èª¿ ---
    API_INSTANCE.on_session_down(handle_session_down)
    API_INSTANCE.quote.on_event(quote_event_handler)

    @API_INSTANCE.on_tick_fop_v1()
    def tick_data_handler(_, tick):
        process_tick(tick)
        #log_tick_debug(tick)

    @API_INSTANCE.on_bidask_fop_v1()
    def bidask_data_handler(_, bidask):
        process_bidask(bidask)
        #log_bidask_debug(bidask)

    # --- è¨‚é–±è¡Œæƒ… ---
    logger.info("â³ è¨‚é–±å°æŒ‡æœŸè¡Œæƒ…...")
    target_contract = API_INSTANCE.Contracts.Futures.TXF.TXFR1
    API_INSTANCE.quote.subscribe(target_contract, quote_type=sj.constant.QuoteType.Tick)
    API_INSTANCE.quote.subscribe(target_contract, quote_type=sj.constant.QuoteType.BidAsk)
    logger.info(f"âœ… å·²è¨‚é–±: {target_contract.code} ({target_contract.name})")
    logger.info("ğŸŸ¢ æœå‹™å·²å•Ÿå‹•ï¼Œç­‰å¾… Tick / BidAsk / ç³»çµ±äº‹ä»¶è§¸ç™¼...")

    # --- æ°¸é ç­‰å¾…äº‹ä»¶å›èª¿ ---
    stop_event = asyncio.Event()  # ç”¨æ–¼ async-friendly Ctrl+C åœæ­¢
    try:
        await stop_event.wait()
    except asyncio.CancelledError:
        logger.info("ğŸ›‘ æ”¶åˆ°åœæ­¢è¨Šè™Ÿ (Ctrl + C)")
    finally:
        # --- å„ªé›…é€€å‡ºæµç¨‹ ---
        logger.info("â³ å„ªé›…é€€å‡ºç¨‹åº...")
        if API_INSTANCE:
            try:
                logger.info("â³ ç™»å‡º API...")
                API_INSTANCE.logout()
            except Exception:
                pass
        logger.info("â³ æ¸…ç©º Kafka ç·©è¡å€...")
        producer.flush()
        logger.info("âœ… ç¨‹å¼çµæŸ")

if __name__ == "__main__":
    asyncio.run(main_async())
