"""
==========================================
TXF Streaming Producer (Class-Based Optimized)
==========================================
Architecture:
  - Pattern: Event-Driven Producer
  - Core: Shioaji (Source) -> Protobuf (Serialize) -> Kafka (Sink)
  - Optimization: Class encapsulation, lazy loading, error isolation
Author: Garrett & Gemini
Last Updated: 2025-11-29
"""

import sys
import signal
import asyncio
import logging
from datetime import datetime
from decimal import Decimal
from typing import Optional, List

# --- Third-party Imports ---
import shioaji as sj
from shioaji import TickFOPv1, BidAskFOPv1
from confluent_kafka import Producer

# --- Local Imports ---
import txf_data_pb2
from config import (
    SHIOAJI_API_KEY, SHIOAJI_SECRET_KEY, 
    KAFKA_BOOTSTRAP_SERVERS, 
    TICK_TOPIC, BIDASK_TOPIC
)

# ==========================================
# 1. Setup & Utilities
# ==========================================

def setup_logging():
    """è¨­å®š Logging (å€åˆ† Dev èˆ‡ Systemd æ¨¡å¼)"""
    # åˆ¤æ–·æ˜¯å¦ç‚ºäº’å‹•æ¨¡å¼ (TTY)
    is_interactive = sys.stdout.isatty()
    
    log_fmt = '%(asctime)s [%(levelname)s] %(message)s' if is_interactive else '[%(levelname)s] %(message)s'
    
    logging.basicConfig(
        level=logging.INFO,
        format=log_fmt,
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[logging.StreamHandler(sys.stdout)]
    )
    # é™ä½ç¬¬ä¸‰æ–¹å¥—ä»¶çš„å™ªéŸ³
    logging.getLogger("shioaji").setLevel(logging.WARNING) 
    return logging.getLogger("TXF_Producer")

logger = setup_logging()

# å¸¸æ•¸å®šç¾©
SCALE = 10000
FATAL_CODES = {1, 2, 8}

# ==========================================
# 2. Core Service Class
# ==========================================

class TxfStreamingService:
    """
    å°æŒ‡æœŸè¡Œæƒ…ä¸²æµæœå‹™
    å°è£äº† API é€£ç·šã€Kafka ç™¼é€èˆ‡éŒ¯èª¤è™•ç†é‚è¼¯
    """
    def __init__(self):
        self.api: Optional[sj.Shioaji] = None
        self.producer: Optional[Producer] = None
        self.running = False
        self._loop = None

    def _init_kafka(self):
        """åˆå§‹åŒ– Kafka Producer"""
        kafka_conf = {
            'bootstrap.servers': KAFKA_BOOTSTRAP_SERVERS,
            'client.id': 'txf-producer-hft',
            'acks': '0',                # æ¥µé€Ÿæ¨¡å¼ (Fire & Forget)
            'linger.ms': 0,             # é›¶å»¶é²
            'compression.type': 'lz4',  # ä½ CPU æ¶ˆè€—å£“ç¸®
            'queue.buffering.max.kbytes': 131072, # 128MB Buffer
            'batch.size': 262144,       # 256KB Batch
            # é‡å° TCP ç¶²è·¯å±¤å„ªåŒ–
            'socket.send.buffer.bytes': 102400,
            'socket.receive.buffer.bytes': 102400,
        }
        try:
            self.producer = Producer(kafka_conf)
            logger.info("âœ… Kafka Producer Initialized")
        except Exception as e:
            logger.critical(f"âŒ Kafka Init Failed: {e}")
            sys.exit(1)

    def _delivery_report(self, err, msg):
        """Kafka Error Callback"""
        if err:
            logger.error(f'âŒ Kafka Delivery Failed: {err}')

    def _to_scaled_int(self, val: Optional[Decimal]) -> int:
        """å¿«é€Ÿè½‰æ› Decimal ç‚º int64"""
        return int(val * SCALE) if val is not None else 0

    # --- Data Processing Callbacks ---

    def process_tick(self, exchange, quote: TickFOPv1):
        """è™•ç† Tick ä¸¦æ¨é€åˆ° Kafka"""
        try:
            if quote.simtrade == 1: return

            # ç›´æ¥åœ¨æ­¤å»ºç«‹ Protobuf ç‰©ä»¶ï¼Œæ¸›å°‘å‡½æ•¸èª¿ç”¨é–‹éŠ·
            tick = txf_data_pb2.Tick()
            tick.code = quote.code
            tick.timestamp_ms = int(quote.datetime.timestamp() * 1000)
            tick.tick_type = int(quote.tick_type)
            tick.close = self._to_scaled_int(quote.close)
            tick.volume = int(quote.volume)
            tick.underlying_price = self._to_scaled_int(quote.underlying_price)
            tick.total_volume = int(quote.total_volume)

            self.producer.produce(
                TICK_TOPIC,
                key=tick.code.encode('utf-8'),
                value=tick.SerializeToString(),
                on_delivery=self._delivery_report
            )
            # é »ç¹ poll(0) é›–ç„¶æ¶ˆè€— CPUï¼Œä½†å° HFT ä¾†èªªèƒ½ä¿æŒ queue æµå‹•
            self.producer.poll(0)

        except Exception as e:
            logger.error(f"âŒ Tick Process Error: {e}")

    def process_bidask(self, exchange, quote: BidAskFOPv1):
        """è™•ç† BidAsk ä¸¦æ¨é€åˆ° Kafka"""
        try:
            if quote.simtrade == 1: return

            ba = txf_data_pb2.BidAsk()
            ba.code = quote.code
            ba.timestamp_ms = int(quote.datetime.timestamp() * 1000)
            ba.bid_total_vol = int(quote.bid_total_vol)
            ba.ask_total_vol = int(quote.ask_total_vol)
            
            # ä½¿ç”¨ extend ç¨å¾®æ¯”è¿´åœˆ append å¿«
            ba.bid_price.extend([self._to_scaled_int(x) for x in quote.bid_price])
            ba.ask_price.extend([self._to_scaled_int(x) for x in quote.ask_price])
            ba.bid_volume.extend(quote.bid_volume)
            ba.ask_volume.extend(quote.ask_volume)
            ba.diff_bid_vol.extend(quote.diff_bid_vol)
            ba.diff_ask_vol.extend(quote.diff_ask_vol)

            self.producer.produce(
                BIDASK_TOPIC,
                key=ba.code.encode('utf-8'),
                value=ba.SerializeToString(),
                on_delivery=self._delivery_report
            )
            self.producer.poll(0)

        except Exception as e:
            logger.error(f"âŒ BidAsk Process Error: {e}")

    # --- System Events ---

    def _handle_session_down(self, reason):
        logger.critical(f"ğŸš¨ Session Down: {reason}. Triggering Systemd Restart.")
        self.shutdown()
        sys.exit(1)

    def _handle_solace_event(self, resp_code, event_code, info, event):
        if event_code in {0, 6, 10, 13, 15, 16, 18}:
            if event_code == 13: logger.info("âœ… Solace Reconnected")
            return
        if event_code == 12: 
            return # Retrying...
        if event_code in FATAL_CODES:
            self._handle_session_down(f"Fatal Code {event_code}: {info}")
        logger.warning(f"âš ï¸ Solace Event {event_code}: {info}")

    # --- Lifecycle Methods ---

    def start(self):
        """å•Ÿå‹•æœå‹™ï¼šç™»å…¥ã€ç¶å®šå›èª¿ã€è¨‚é–±"""
        self._init_kafka()
        
        logger.info("ğŸ”‘ Logging into Shioaji...")
        self.api = sj.Shioaji(simulation=True)
        try:
            self.api.login(api_key=SHIOAJI_API_KEY, secret_key=SHIOAJI_SECRET_KEY)
            logger.info("âœ… Login Success")
        except Exception as e:
            logger.critical(f"âŒ Login Failed: {e}")
            sys.exit(1)

        # ç¶å®šäº‹ä»¶
        self.api.on_session_down(self._handle_session_down)
        self.api.quote.on_event(self._handle_solace_event)
        
        # ç¶å®šæ•¸æ“šå›èª¿ (ç›´æ¥ç¶å®šæ–¹æ³•ï¼Œä¸éœ€é¡å¤–è£é£¾å™¨)
        self.api.quote.set_on_tick_fop_v1_callback(self.process_tick)
        self.api.quote.set_on_bidask_fop_v1_callback(self.process_bidask)

        # è¨‚é–±
        logger.info("â³ Subscribing to TXF...")
        contract = self.api.Contracts.Futures.TXF.TXFR1
        self.api.quote.subscribe(contract, quote_type=sj.constant.QuoteType.Tick)
        self.api.quote.subscribe(contract, quote_type=sj.constant.QuoteType.BidAsk)
        logger.info(f"âœ… Subscribed: {contract.name} ({contract.code})")
        
        self.running = True

    def shutdown(self):
        """å„ªé›…é—œé–‰è³‡æº"""
        logger.info("â³ Shutting down services...")
        if self.api:
            try:
                logger.info("Logout API...")
                self.api.logout()
            except: pass
        
        if self.producer:
            logger.info("Flushing Kafka...")
            self.producer.flush()
        logger.info("ğŸ‘‹ Bye")

# ==========================================
# 3. Main Entry Point
# ==========================================

async def main():
    service = TxfStreamingService()
    service.start()
    
    # å»ºç«‹ Async Event ä¾†ç­‰å¾…åœæ­¢è¨Šè™Ÿ
    stop_event = asyncio.Event()
    loop = asyncio.get_running_loop()

    def signal_handler(*args):
        logger.info("ğŸ›‘ Signal received, stopping...")
        loop.call_soon_threadsafe(stop_event.set)

    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)

    logger.info("ğŸŸ¢ Service is running (Ctrl+C to stop)")
    
    # åœ¨é€™è£¡å¯ä»¥åŠ å…¥ Watchdog é‚è¼¯ (å¦‚éœ€è¦)
    # asyncio.create_task(watchdog(service, stop_event))
    
    await stop_event.wait()
    service.shutdown()

if __name__ == "__main__":
    asyncio.run(main())